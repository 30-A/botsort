{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7774b7-5c0b-416e-b5ef-2da71d14c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_sliced_prediction, get_prediction\n",
    "from moviepy.editor import VideoFileClip, ImageSequenceClip\n",
    "\n",
    "from src.bot_sort import BoTSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a8d085-4fe4-4d53-b65d-9a9c166c122a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ObjectDetector:\n",
    "    def __init__(self, config_path, checkpoint_path, use_slicing=True):\n",
    "        self.config_path = config_path\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.use_slicing = use_slicing\n",
    "        self._initialize_model()\n",
    "\n",
    "    def _initialize_model(self):\n",
    "        self.model = AutoDetectionModel.from_pretrained(\n",
    "            model_type='mmdet',\n",
    "            model_path=self.checkpoint_path,\n",
    "            config_path=self.config_path,\n",
    "            confidence_threshold=0.4,\n",
    "            category_mapping=None,\n",
    "            image_size=None,\n",
    "            device='cuda:0'\n",
    "        )\n",
    "        self.class_labels = self.model.model.model.dataset_meta.get(\"classes\")\n",
    "        self.class_colors = self.model.model.model.dataset_meta.get(\"palette\")\n",
    "        self.class_colors = {i: tuple(color) for i, color in enumerate(self.class_colors)}\n",
    "        self.class_labels = {i: label for i, label in enumerate(self.class_labels)}\n",
    "\n",
    "    def detect(self, bgr_frame, slice_height=720, slice_width=720, overlap_height_ratio=0.1, overlap_width_ratio=0.1):\n",
    "        if self.use_slicing:\n",
    "            result = get_sliced_prediction(\n",
    "                bgr_frame,\n",
    "                self.model,\n",
    "                slice_height=slice_height,\n",
    "                slice_width=slice_width,\n",
    "                postprocess_match_threshold=0.7,\n",
    "                postprocess_type=\"NMM\",\n",
    "                postprocess_class_agnostic=True,\n",
    "                overlap_height_ratio=overlap_height_ratio,\n",
    "                overlap_width_ratio=overlap_width_ratio,\n",
    "                verbose=0\n",
    "            )\n",
    "        else:\n",
    "            result = get_prediction(bgr_frame, self.model)\n",
    "        \n",
    "        object_prediction_list = result.object_prediction_list\n",
    "        detections = []\n",
    "        for obj in object_prediction_list:\n",
    "            bbox = obj.bbox.to_voc_bbox()\n",
    "            score = obj.score.value\n",
    "            label = obj.category.id\n",
    "            detections.append((np.array([bbox[0], bbox[1], bbox[2], bbox[3]]), score, label))\n",
    "        return detections\n",
    "\n",
    "    def get_class_labels(self):\n",
    "        return self.class_labels\n",
    "\n",
    "    def get_class_colors(self):\n",
    "        return self.class_colors\n",
    "\n",
    "class Tracker:\n",
    "    def __init__(self):\n",
    "        self.track_high_thresh = 0.6\n",
    "        self.track_low_thresh = 0.1\n",
    "        self.new_track_thresh = 0.6\n",
    "        self.track_buffer = 30\n",
    "        self.proximity_thresh = 0.5\n",
    "        self.appearance_thresh = 0.25\n",
    "        self.with_reid = False\n",
    "        self.device = 'cuda:0'\n",
    "        self.cmc_method = 'orb'\n",
    "        self.name = 'video'\n",
    "        self.ablation = False\n",
    "        self.mot20 = False\n",
    "        self.match_thresh = 0.8\n",
    "        self.tracker = BoTSORT(self)\n",
    "\n",
    "    def update(self, detections, frame):\n",
    "        return self.tracker.update(detections, frame)\n",
    "\n",
    "class Counter:\n",
    "    def __init__(self, class_labels, class_colors, line_offset=0, draw_line=True):\n",
    "        self.class_labels = class_labels\n",
    "        self.class_colors = class_colors\n",
    "        self.line_offset = line_offset\n",
    "        self.crossed_line_ids = {cls_id: set() for cls_id in class_labels}\n",
    "        self.track_class_mapping = {}\n",
    "        self.track_trails = {}\n",
    "        self.draw_line = draw_line\n",
    "\n",
    "    def count_objects(self, tracked_objects, frame_width, frame):\n",
    "        vertical_line_x = (frame_width // 2) + self.line_offset\n",
    "\n",
    "        for t in tracked_objects:\n",
    "            track_id = int(t.track_id)\n",
    "            cls = t.cls\n",
    "\n",
    "            if track_id not in self.track_class_mapping:\n",
    "                self.track_class_mapping[track_id] = cls\n",
    "                self.track_trails[track_id] = []\n",
    "\n",
    "            bbox = t.tlwh\n",
    "            center = (int(bbox[0] + bbox[2] // 2), int(bbox[1] + bbox[3] // 2))\n",
    "            self.track_trails[track_id].append(center)\n",
    "\n",
    "            if len(self.track_trails[track_id]) > 1:\n",
    "                prev_center = self.track_trails[track_id][-2]\n",
    "                if (prev_center[0] < vertical_line_x and center[0] >= vertical_line_x) or (prev_center[0] > vertical_line_x and center[0] <= vertical_line_x):\n",
    "                    self.crossed_line_ids[cls].add(track_id)\n",
    "\n",
    "        if self.draw_line:\n",
    "            cv2.line(frame, (vertical_line_x, 0), (vertical_line_x, frame.shape[0]), (0, 255, 0), 2)\n",
    "\n",
    "        return self.track_trails, self.track_class_mapping\n",
    "\n",
    "    def get_counts(self):\n",
    "        return {self.class_labels[cls]: len(self.crossed_line_ids[cls]) for cls in self.class_labels}\n",
    "\n",
    "class Plotting:\n",
    "    def __init__(self, logo_path):\n",
    "        self.logo = cv2.imread(logo_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    def resize_logo(self, logo, new_width):\n",
    "        h, w = logo.shape[:2]\n",
    "        scale = new_width / w\n",
    "        new_height = int(h * scale)\n",
    "        logo = cv2.resize(logo, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "        return logo\n",
    "\n",
    "    def add_logo(self, frame, logo_width=235, alpha=0.3, padding=7, top_space=20):\n",
    "        logo_resized = self.resize_logo(self.logo, logo_width)\n",
    "        h, w = logo_resized.shape[:2]\n",
    "        x = frame.shape[1] - w - padding\n",
    "        y = padding + top_space\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (x - padding, y - padding), (x + w + padding, y + h + padding), (255, 255, 255), -1)\n",
    "        cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
    "        logo_rgb = logo_resized[..., :3]\n",
    "        alpha_mask = logo_resized[..., 3] / 255.0\n",
    "        roi = frame[y:y+h, x:x+w]\n",
    "        for c in range(3):\n",
    "            roi[:, :, c] = roi[:, :, c] * (1 - alpha_mask) + logo_rgb[:, :, c] * alpha_mask\n",
    "        frame[y:y+h, x:x+w] = roi\n",
    "        return frame\n",
    "\n",
    "    def add_text(self, frame, text_lines, class_labels, class_colors, x_offset, y_offset, alpha=0.3, padding=7, top_space=20):\n",
    "        y_offset += top_space\n",
    "        max_text_width = max([cv2.getTextSize(line, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0][0] for line in text_lines])\n",
    "        total_text_height = len(text_lines) * 30\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (x_offset - padding, y_offset - padding), (x_offset + max_text_width + 50 + padding, y_offset + total_text_height + padding), (255, 255, 255), -1)\n",
    "        cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
    "        current_y = y_offset + 30\n",
    "        for line in text_lines:\n",
    "            class_name = line.split(':')[0].strip()\n",
    "            color = class_colors[list(class_labels.values()).index(class_name)]\n",
    "            circle_radius = 8\n",
    "            circle_y_offset = 10\n",
    "            cv2.circle(frame, (x_offset + 15, current_y - circle_y_offset), circle_radius, color, -1)\n",
    "            cv2.putText(frame, line, (x_offset + 30, current_y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "            current_y += 30\n",
    "        return frame\n",
    "\n",
    "    def draw_tracks_and_ids(self, frame, tracked_objects, track_trails, track_class_mapping, class_labels, class_colors):\n",
    "        for t in tracked_objects:\n",
    "            bbox = t.tlwh\n",
    "            track_id = int(t.track_id)\n",
    "            cls = track_class_mapping[track_id]\n",
    "            x1, y1, w, h = map(int, bbox)\n",
    "            x2, y2 = x1 + w, y1 + h\n",
    "            label = f'{track_id}'\n",
    "            color = class_colors[cls]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
    "            cv2.rectangle(frame, (x1, y1 - text_height - baseline), (x1 + text_width, y1), color, -1)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "            for point in track_trails[track_id]:\n",
    "                cv2.circle(frame, point, 2, color, -1)\n",
    "        return frame\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self, detector, tracker, counter, plotting):\n",
    "        self.detector = detector\n",
    "        self.tracker = tracker\n",
    "        self.counter = counter\n",
    "        self.plotting = plotting\n",
    "\n",
    "    def process_frame(self, frame, frame_width):\n",
    "        # Create a writable copy of the frame\n",
    "        frame = frame.copy()\n",
    "\n",
    "        # Perform detection\n",
    "        detections = self.detector.detect(frame)  # Pass BGR frame directly\n",
    "        output_results = np.array([[*bbox, score, label] for bbox, score, label in detections])\n",
    "\n",
    "        # Update the tracker\n",
    "        tracked_objects = self.tracker.update(output_results, frame)\n",
    "\n",
    "        # Count objects\n",
    "        track_trails, track_class_mapping = self.counter.count_objects(tracked_objects, frame_width, frame)\n",
    "\n",
    "        # Draw tracking results and trails on the frame (BGR format)\n",
    "        frame = self.plotting.draw_tracks_and_ids(frame, tracked_objects, track_trails, track_class_mapping, self.counter.class_labels, self.counter.class_colors)\n",
    "\n",
    "        # Get counts and add text to the frame\n",
    "        counts = self.counter.get_counts()\n",
    "        text_lines = [f\"{cls}: {count}\" for cls, count in counts.items()]\n",
    "        frame = self.plotting.add_text(frame, text_lines, self.counter.class_labels, self.counter.class_colors, x_offset=10, y_offset=10)\n",
    "\n",
    "        # Add logo to the frame at the top right corner with a fixed width\n",
    "        frame = self.plotting.add_logo(frame)\n",
    "\n",
    "        return frame, tracked_objects\n",
    "\n",
    "    def process_video(self, video_path, output_path, save_video=True, save_csv=True, csv_output_path=None):\n",
    "        clip = VideoFileClip(video_path)\n",
    "        frame_width = clip.w\n",
    "        fps = clip.fps\n",
    "        total_frames = int(clip.fps * clip.duration)\n",
    "        \n",
    "        csv_data = [] if save_csv else None\n",
    "\n",
    "        processed_frames = []\n",
    "        frame_id = 1\n",
    "        with tqdm(total=total_frames, desc=\"Processing video\", unit=\"frame\") as pbar:\n",
    "            for frame in clip.iter_frames():\n",
    "                processed_frame, tracked_objects = self.process_frame(frame, frame_width)\n",
    "\n",
    "                if save_csv:\n",
    "                    self._save_csv(csv_data, frame_id, tracked_objects, csv_output_path)\n",
    "\n",
    "                processed_frames.append(processed_frame)\n",
    "                pbar.update(1)\n",
    "                frame_id += 1\n",
    "\n",
    "        if save_video:\n",
    "            output_clip = ImageSequenceClip(processed_frames, fps=fps)\n",
    "            output_clip.write_videofile(output_path, codec='libx264')\n",
    "\n",
    "    def _save_csv(self, csv_data, frame_id, tracked_objects, csv_output_path):\n",
    "        for obj in tracked_objects:\n",
    "            bbox = obj.tlwh\n",
    "            csv_data.append([int(frame_id), int(obj.track_id), round(bbox[0], 2), round(bbox[1], 2), round(bbox[2], 2), round(bbox[3], 2), int(obj.cls)])\n",
    "        df = pd.DataFrame(csv_data, columns=[\"frame_id\", \"track_id\", \"x\", \"y\", \"w\", \"h\", \"class_id\"])\n",
    "        df.to_csv(csv_output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b77ae81-3026-4ced-9b29-46b889a1da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and processing configurations\n",
    "config_path = '/home/jupyter/tomato_weight/ddod_r152_Solanumlycopersicum13.py'\n",
    "checkpoint_path = '/home/jupyter/tomato_weight/best_coco_bbox_mAP_50_epoch_1176.pth'\n",
    "logo_path = '/home/jupyter/logo.png'\n",
    "video_path = '/home/jupyter/tomato_3.mp4'\n",
    "output_path = '/home/jupyter/tomato_output.mp4'\n",
    "csv_output_path = '/home/jupyter/tomato_output.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b7f455-43ce-44fd-9017-3cd1098b89b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize components\n",
    "detector = ObjectDetector(config_path=config_path, checkpoint_path=checkpoint_path, use_slicing=True)\n",
    "tracker = Tracker()\n",
    "counter = Counter(detector.get_class_labels(), detector.get_class_colors(), line_offset=0, draw_line=True)\n",
    "plotting = Plotting(logo_path)\n",
    "\n",
    "video_processor = VideoProcessor(detector, tracker, counter, plotting)\n",
    "\n",
    "# Process video\n",
    "video_processor.process_video(video_path=video_path,\n",
    "                              output_path=output_path,\n",
    "                              save_video=True,\n",
    "                              save_csv=True,\n",
    "                              csv_output_path=csv_output_path)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
